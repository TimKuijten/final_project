{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dateparser\n",
    "import datetime as datetime\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REDDIT THREADS\n",
    "df_reddit1 = pd.read_csv('df_reddit1.csv')\n",
    "df_reddit2 = pd.read_csv('df_reddit2.csv')\n",
    "df_reddit3 = pd.read_csv('df_reddit3.csv')\n",
    "df_reddit4 = pd.read_csv('df_reddit4.csv')\n",
    "df_reddit5 = pd.read_csv('df_reddit5.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reddit = pd.concat([df_reddit1, df_reddit2, df_reddit3, df_reddit4, df_reddit5], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REDDIT COMMENTS\n",
    "df_reddit_comments1 = pd.read_csv('erpc1.csv')\n",
    "df_reddit_comments2 = pd.read_csv('erpc2.csv')\n",
    "df_reddit_comments3 = pd.read_csv('erpc3.csv')\n",
    "df_reddit_comments4 = pd.read_csv('erpc4.csv')\n",
    "df_reddit_comments5 = pd.read_csv('erpc5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reddit_comments = pd.concat([df_reddit_comments1, df_reddit_comments2, df_reddit_comments3, df_reddit_comments4, df_reddit_comments5], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REDDIT COMMENTS\n",
    "df_reddit_opening_post1 = pd.read_csv('erpi1.csv')\n",
    "df_reddit_opening_post2 = pd.read_csv('erpi2.csv')\n",
    "df_reddit_opening_post3 = pd.read_csv('erpi3.csv')\n",
    "df_reddit_opening_post4 = pd.read_csv('erpi4.csv')\n",
    "df_reddit_opening_post5 = pd.read_csv('erpi5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_opening_posts = pd.concat([df_reddit_opening_post1, df_reddit_opening_post2, df_reddit_opening_post3, df_reddit_opening_post4, df_reddit_opening_post5], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_reddit_threads(df):\n",
    "    # Initialize SentimentIntensityAnalyzer\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    # Remove duplicates and rows with 'Error loading' in the 'Link' column\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df = df[df['Link'] != 'Error loading'].reset_index(drop=True)\n",
    "\n",
    "    # Calculate Title sentiment and Title subjectivity\n",
    "    df['Title sentiment'] = df['Title'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "    df['Title subjectivity'] = df['Title'].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reddit_threads = clean_reddit_threads(df_reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reddit_threads.to_csv('./cleaned/df_reddit_threads', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_reddit_comments(df):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    df['date'] = df['date'].apply(lambda x: dateparser.parse(x).strftime('%d-%m-%Y'))\n",
    "    df = df[df['Name'] != 'AutoModerator']\n",
    "    df['comment2'] = df['comment2'].astype(str)\n",
    "    df['Comment sentiment'] = df['comment2'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "    df['Comment subjectivity'] = df['comment2'].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "\n",
    "    df = df.rename(columns={'Name': 'Username', \n",
    "                            'upvotes': 'Upvotes', \n",
    "                            'date': 'Date', \n",
    "                            'description': 'Description', \n",
    "                            'url': 'Link',\n",
    "                            'comment2': 'Comment'})\n",
    "\n",
    "    # Reorder columns\n",
    "    df = df.reindex(columns=['Username','Date','Comment','Comment sentiment','Comment subjectivity','Upvotes','Link'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tim_K\\AppData\\Local\\Temp\\ipykernel_9740\\2760482211.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['comment2'] = df['comment2'].astype(str)\n",
      "C:\\Users\\Tim_K\\AppData\\Local\\Temp\\ipykernel_9740\\2760482211.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Comment sentiment'] = df['comment2'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
      "C:\\Users\\Tim_K\\AppData\\Local\\Temp\\ipykernel_9740\\2760482211.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Comment subjectivity'] = df['comment2'].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n"
     ]
    }
   ],
   "source": [
    "clean_comments = clean_reddit_comments(df_reddit_comments1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Comment sentiment</th>\n",
       "      <th>Comment subjectivity</th>\n",
       "      <th>Upvotes</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hankhank1</td>\n",
       "      <td>14-03-2016</td>\n",
       "      <td>Will a great power war erupt within the next f...</td>\n",
       "      <td>0.0516</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.6k</td>\n",
       "      <td>https://www.reddit.com/r/IAmA/comments/4m24zv/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNU_AMA</td>\n",
       "      <td>14-03-2016</td>\n",
       "      <td>UNU SAYS:  YES</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.3k</td>\n",
       "      <td>https://www.reddit.com/r/IAmA/comments/4m24zv/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>viewofthecouncil</td>\n",
       "      <td>14-03-2016</td>\n",
       "      <td>'Great power war' is incredibly vague. The Col...</td>\n",
       "      <td>-0.5984</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>41</td>\n",
       "      <td>https://www.reddit.com/r/IAmA/comments/4m24zv/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Professor_Kickass</td>\n",
       "      <td>14-03-2016</td>\n",
       "      <td>Will a manned Mars mission take place in the n...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.3k</td>\n",
       "      <td>https://www.reddit.com/r/IAmA/comments/4m24zv/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNU_AMA</td>\n",
       "      <td>14-03-2016</td>\n",
       "      <td>UNU SAYS:  YES</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.2k</td>\n",
       "      <td>https://www.reddit.com/r/IAmA/comments/4m24zv/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35701</th>\n",
       "      <td>CafeconWalleche</td>\n",
       "      <td>14-03-2019</td>\n",
       "      <td>Yeah but so can dogs, artificial intelligence ...</td>\n",
       "      <td>0.7220</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/Futurology/comments/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35702</th>\n",
       "      <td>SoonerTech</td>\n",
       "      <td>14-03-2019</td>\n",
       "      <td>But you can’t sue an AI. There were studies do...</td>\n",
       "      <td>0.5023</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/Futurology/comments/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35703</th>\n",
       "      <td>uDrinkMyMilkshake</td>\n",
       "      <td>14-03-2019</td>\n",
       "      <td>just give it some time,  r/futurology will fin...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>https://www.reddit.com/r/Futurology/comments/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35704</th>\n",
       "      <td>notaredditthrowaway</td>\n",
       "      <td>14-03-2019</td>\n",
       "      <td>Looks like someone already did.</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/Futurology/comments/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35705</th>\n",
       "      <td>asapgrey</td>\n",
       "      <td>14-03-2019</td>\n",
       "      <td>But by by the time we have access to this tech...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-1</td>\n",
       "      <td>https://www.reddit.com/r/Futurology/comments/a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35682 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Username        Date  \\\n",
       "0                Hankhank1  14-03-2016   \n",
       "1                  UNU_AMA  14-03-2016   \n",
       "2         viewofthecouncil  14-03-2016   \n",
       "3        Professor_Kickass  14-03-2016   \n",
       "4                  UNU_AMA  14-03-2016   \n",
       "...                    ...         ...   \n",
       "35701      CafeconWalleche  14-03-2019   \n",
       "35702           SoonerTech  14-03-2019   \n",
       "35703    uDrinkMyMilkshake  14-03-2019   \n",
       "35704  notaredditthrowaway  14-03-2019   \n",
       "35705             asapgrey  14-03-2019   \n",
       "\n",
       "                                                 Comment  Comment sentiment  \\\n",
       "0      Will a great power war erupt within the next f...             0.0516   \n",
       "1                                         UNU SAYS:  YES             0.4019   \n",
       "2      'Great power war' is incredibly vague. The Col...            -0.5984   \n",
       "3      Will a manned Mars mission take place in the n...             0.0000   \n",
       "4                                         UNU SAYS:  YES             0.4019   \n",
       "...                                                  ...                ...   \n",
       "35701  Yeah but so can dogs, artificial intelligence ...             0.7220   \n",
       "35702  But you can’t sue an AI. There were studies do...             0.5023   \n",
       "35703  just give it some time,  r/futurology will fin...             0.0000   \n",
       "35704                    Looks like someone already did.             0.3612   \n",
       "35705  But by by the time we have access to this tech...             0.0000   \n",
       "\n",
       "       Comment subjectivity Upvotes  \\\n",
       "0                  0.375000    1.6k   \n",
       "1                  0.000000    1.3k   \n",
       "2                  0.750000      41   \n",
       "3                  0.000000    1.3k   \n",
       "4                  0.000000    1.2k   \n",
       "...                     ...     ...   \n",
       "35701              0.533333       0   \n",
       "35702              0.500000       0   \n",
       "35703              0.000000      -1   \n",
       "35704              0.000000       0   \n",
       "35705              0.600000      -1   \n",
       "\n",
       "                                                    Link  \n",
       "0      https://www.reddit.com/r/IAmA/comments/4m24zv/...  \n",
       "1      https://www.reddit.com/r/IAmA/comments/4m24zv/...  \n",
       "2      https://www.reddit.com/r/IAmA/comments/4m24zv/...  \n",
       "3      https://www.reddit.com/r/IAmA/comments/4m24zv/...  \n",
       "4      https://www.reddit.com/r/IAmA/comments/4m24zv/...  \n",
       "...                                                  ...  \n",
       "35701  https://www.reddit.com/r/Futurology/comments/a...  \n",
       "35702  https://www.reddit.com/r/Futurology/comments/a...  \n",
       "35703  https://www.reddit.com/r/Futurology/comments/a...  \n",
       "35704  https://www.reddit.com/r/Futurology/comments/a...  \n",
       "35705  https://www.reddit.com/r/Futurology/comments/a...  \n",
       "\n",
       "[35682 rows x 7 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_comments.to_csv('./cleaned/df_reddit_comments', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_reddit_opening_post(df):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    df['Date'] = df['Date'].apply(lambda x: dateparser.parse(x).strftime('%d-%m-%Y'))\n",
    "    df['Message'] = df['Message'].astype(str)\n",
    "    df['Post sentiment'] = df['Message'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "    df['Post subjectivity'] = df['Message'].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "\n",
    "    df = df.rename(columns={'Message': 'Post', \n",
    "                            'URL': 'Link'})\n",
    "\n",
    "    # Reorder columns\n",
    "    df = df.reindex(columns=['Username','Title','Date', 'Post', 'Post sentiment','Post subjectivity','Upvotes', 'Comments','Link'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_reddit_opening_posts = clean_reddit_opening_post(reddit_opening_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_reddit_opening_posts.to_csv('./cleaned/df_reddit_comments', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
